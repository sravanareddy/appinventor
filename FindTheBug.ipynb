{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson\n",
    "import numpy \n",
    "import datetime\n",
    "from collections import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load summary data of all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n"
     ]
    }
   ],
   "source": [
    "summaries = {}\n",
    "ctr = 0\n",
    "for line in open('user_project_summaries.json'): # lazy iteration because the file is large\n",
    "    ctr += 1\n",
    "    summaries.update(ujson.loads(line))  \n",
    "    print ctr,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The languages labels are inferred from the `namestrings_to_langs.py` script using `langid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang data created with 43410 users and 12 languages set([u'el', u'fr', u'en', u'zh', u'pt', u'la', u'ca', u'de', u'ko', u'it', u'th', u'es'])\n"
     ]
    }
   ],
   "source": [
    "isocodes = ujson.load(open('isocodes.json'))  # mapping from  iso code to language name\n",
    "user_langs = ujson.load(open('user_inferredlangs.json'))  # mapping from userid to inferred language\n",
    "# remove uncommon languages\n",
    "lang_counts = Counter()\n",
    "for user in user_langs:\n",
    "    lang = user_langs[user]\n",
    "    lang_counts[lang] += 1\n",
    "    \n",
    "user_langs = {user: lang for user, lang in user_langs.items() if lang_counts[lang]>=250 and user in summaries}\n",
    "langset = set(user_langs.values())\n",
    "print 'lang data created with', len(user_langs), 'users and', len(langset), 'languages', langset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep users with language labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 43410 users\n"
     ]
    }
   ],
   "source": [
    "summaries = {user: summaries[user] for user in summaries if user in user_langs}\n",
    "print 'Filtered to', len(summaries), 'users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a dictionary, with each language as a key and a list of users who use that language as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_dict = {}\n",
    "for user in summaries: \n",
    "    lang = user_langs[user]\n",
    "    if lang not in lang_dict: \n",
    "        lang_dict[lang] = []\n",
    "    lang_dict[lang].append(summaries[user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with Chinese users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chin_users = lang_dict['zh']\n",
    "# c = Counter()\n",
    "# for summary in chin_users: \n",
    "#     for project in summary: \n",
    "#         c.update([summary[project]['**Project Name']])\n",
    "\n",
    "#print c.most_common(100)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 151351 unqiue project names 3582 contain the prefix 'ex_' most likely indicating a series of tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chinese_examples = [entry for entry in c if 'ex_' in entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582\n"
     ]
    }
   ],
   "source": [
    "print len(chinese_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from features import *\n",
    "import features\n",
    "reload(features)\n",
    "import sys, os\n",
    "sys.path.append(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time utilities\n",
    "def convert_time(el):\n",
    "    \"\"\"Human readable time\"\"\"\n",
    "    el = int(str(el)[:10])\n",
    "    return datetime.date.fromtimestamp(el)\n",
    "\n",
    "def timediff(t1, t2):\n",
    "    \"\"\"difference between times (millisec precision) as days\"\"\"\n",
    "    return (t1-t2)/(86400.*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_tutorials = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9\n"
     ]
    }
   ],
   "source": [
    "if filter_tutorials: \n",
    "    not_tutorials = {}\n",
    "\n",
    "    for i in range(10): \n",
    "        print i, \n",
    "        notT_list = ujson.load(open('tutorial_comparisons/nottutorials_' + str(i) +'.json'))\n",
    "        for entry in notT_list: \n",
    "            if entry[0] not in summaries:\n",
    "                continue\n",
    "            proj_name = entry[1].split(\"_summary.json\")[0]\n",
    "#             if entry[0] not in not_tutorials: \n",
    "                not_tutorials[entry[0]] = {}\n",
    "            try: \n",
    "                not_tutorials[entry[0]][proj_name] = summaries[entry[0]][proj_name]\n",
    "            except KeyError: \n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_featfuncs(funclist):\n",
    "    def combined(user):\n",
    "        basedict = funclist[0](user)\n",
    "        for f in funclist[1:]:\n",
    "            basedict.update(f(user))\n",
    "        return basedict\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllProjects(userID, no_tutorials): \n",
    "    \"\"\"list of projects sorted by creation times\"\"\"\n",
    "    if (no_tutorials):\n",
    "        try: \n",
    "            projectlist = not_tutorials[userID].values()\n",
    "        except:\n",
    "            print userID\n",
    "    else: \n",
    "        projectlist = summaries[userID].values()\n",
    "    return sorted(projectlist,\n",
    "                  key=lambda project: project['**created']) \n",
    "\n",
    "def userDuration(projectlist):\n",
    "    \"\"\"get the duration (difference between last and earliest creation dates)\"\"\"\n",
    "    return timediff(projectlist[-1]['**created'], projectlist[0]['**created'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAllProjects(userID, filter_tutorials=False): \n",
    "    \"\"\"list of projects sorted by creation times\"\"\"\n",
    "    projectlist = summaries[userID].values()\n",
    "    if filter_tutorials:\n",
    "        projectlist = [projectname for projectname in projectlist if projectname not in not_tutorials]\n",
    "    return sorted(projectlist,\n",
    "                  key=lambda project: project['**created']) \n",
    "\n",
    "def userDuration(projectlist):\n",
    "    \"\"\"get the duration (difference between last and earliest creation dates)\"\"\"\n",
    "    return timediff(projectlist[-1]['**created'], projectlist[0]['**created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "langgroups = {'es': 'eur',\n",
    "              'pt': 'eur', \n",
    "              'it': 'eur', \n",
    "              'de': 'eur', \n",
    "              'fr': 'eur', \n",
    "              'ca': 'eur', \n",
    "              'el': 'eur', \n",
    "              'nl': 'eur', \n",
    "              'pl': 'eur',\n",
    "              'en': 'eur',\n",
    "              'ru': 'eur',\n",
    "              'ko': 'asia', \n",
    "              'zh': 'asia', \n",
    "              'ja': 'asia', \n",
    "              'th': 'asia'}\n",
    "langgroup_num_map = {'eur': 0, 'asia': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_labels():\n",
    "    return {user: langgroups[lang] for user, lang in user_langs.items() if lang in langgroups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def projectLengthFeatures(projects):\n",
    "    \"\"\"moments of project lengths and intervals for a user, as well as number of projects\"\"\"\n",
    "    lengths = getProjectLengths(projects)\n",
    "    intervals = getProjectIntervals(projects)\n",
    "    \n",
    "    userDict = {} \n",
    "    userDict[\"mean of lengths\"] = numpy.mean(lengths)\n",
    "    userDict[\"stddev of lengths\"] = numpy.std(lengths)\n",
    "    userDict[\"mean of intervals\"] = numpy.mean(lengths)\n",
    "    userDict[\"stddev of intervals\"] = numpy.std(lengths)\n",
    "    \n",
    "    userDict[\"num projects\"] = numProjects(projects)\n",
    "    \n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dayAnalysisFeatures(projects):\n",
    "    \"\"\"number of projects on each day of the week, and the proportion of them on a weekday\"\"\"\n",
    "    byday = numOnDay(projects)\n",
    "\n",
    "    userDict = {day: byday[i] for i, day in enumerate([\"Monday\", \n",
    "                                                       \"Tuesday\", \n",
    "                                                       \"Wednesday\", \n",
    "                                                       \"Thursday\", \n",
    "                                                       \"Friday\", \n",
    "                                                       \"Saturday\", \n",
    "                                                       \"Sunday\"])}\n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decileProjects(projects):\n",
    "    numbins = 10\n",
    "    hist = projectsPerUserPeriod(projects, bins=numbins)\n",
    "    \n",
    "    userDict = {'decile '+str(i+1): hist[i] for i in range(numbins)}\n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deltaDeciles(decileDict, name):\n",
    "    values = sortDeciles(decileDict)\n",
    "    deltas = {}\n",
    "    for i in range(10): \n",
    "        if i== 0: pass\n",
    "        else: deltas[str(i) + \" \" + name] = values[i]-values[i-1]\n",
    "    return deltas\n",
    "\n",
    "\n",
    "def sortDeciles(decileDict):\n",
    "    deciles_sorted = []\n",
    "    keys = decileDict.keys()\n",
    "    for key in keys: \n",
    "        deciles_sorted.insert(int(key[-1]), decileDict[key])\n",
    "    return deciles_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summaryOBlockDecile(projects): \n",
    "    hist = decileOrphanBlocks(projects)\n",
    "    userDict = {'Orphan Decile '+str(i+1): hist[i] for i in range(10)}\n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summaryDecileTLBlocks(projects): \n",
    "    hist = decileTypesTopLevelBlocks(projects)\n",
    "    userDict = {'TopLevel Decile '+str(i+1): hist[i] for i in range(10)}\n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summaryDecileNumScreens(projects): \n",
    "    hist = decileNumScreens(projects)\n",
    "    userDict = {'NumScreens Decile '+str(i+1): hist[i] for i in range(10)}\n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summaryDeltasTLBlocks(projects): \n",
    "    tlblocks = summaryDecileTLBlocks(projects)\n",
    "    return deltaDeciles(tlblocks, \"TL blocks delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summaryDeltasOBlock(projects): \n",
    "    oblock = summaryOBlockDecile(projects)\n",
    "    return deltaDeciles(oblock,\"O blocks delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summaryDeltasNumScreens(projects): \n",
    "    numscreens = summaryDecileNumScreens(projects)\n",
    "    return deltaDeciles(numscreens, \"numscreens blocks delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summaryAverages(projects):\n",
    "    userDict = {} \n",
    "    userDict[\"mean of numScreens\"] = numpy.mean(getNumScreens(projects))\n",
    "    userDict[\"NB\"] = averageNumBlocks(projects)\n",
    "    userDict[\"OB\"] = getAverageOrphanBlocks(projects)\n",
    "    \n",
    "    userDict[\"TL\"] = getAverageTypeTLBlocks(projects)\n",
    "    userDict[\"TL2\"] = getAverageNumTLBlocks(projects)\n",
    "    \n",
    "    userDict[\"NC\"] = averageNumComponents(projects)\n",
    "    userDict[\"NTC\"] = averageNumTypeComponents(projects)\n",
    "\n",
    "    userDict[\"MC\"] = aveNumMediaAssets(projects)\n",
    "    \n",
    "    userDict[\"NP\"] = averageNumProcedures(projects)\n",
    "    userDict[\"NS\"] = averageNumStrings(projects) \n",
    "        \n",
    "    varList = getAllVariables(projects)\n",
    "    userDict[\"local vars\"] = varList[0]\n",
    "    userDict[\"global vars\"] = varList[1]\n",
    " \n",
    "\n",
    "\n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classesFeaturizers(projects): \n",
    "    userDict = {} \n",
    "    classes = getClasses(projects)\n",
    "    cList = ['TableArrangement', 'DatePicker', 'Canvas', \n",
    "             'CheckBox', 'Web', 'Clock', 'BluetoothServer', \n",
    "             'ActivityStarter', 'Texting', 'Label', 'Spinner', \n",
    "             'Camera', 'BluetoothClient', 'PhoneCall', 'LocationSensor', \n",
    "             'VerticalArrangement', 'HorizontalArrangement', 'Sharing', \n",
    "             'TextToSpeech', 'GoogleMap', 'Slider', 'OrientationSensor', \n",
    "             'ListView', 'PhoneNumberPicker', 'TinyDB', 'NxtDirectCommands', \n",
    "             'Sound', 'ListPicker', 'SpeechRecognizer', 'Button', 'WebViewer',\n",
    "             'BarcodeScanner', 'NxtDrive', 'Camcorder', 'Notifier', 'TextBox',\n",
    "             'AccelerometerSensor', 'Image', 'VideoPlayer', 'TinyWebDB',\n",
    "             'Player', 'File', 'YandexTranslate']\n",
    "   \n",
    "    for key in cList: \n",
    "        userDict[key] = classes[key]\n",
    "        \n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def allBlocksFeaturizer(projects):\n",
    "    userDict = {}\n",
    "    with open('top_500_blocks.json') as data_file:    \n",
    "        block_list = json.load(data_file)\n",
    "\n",
    "    all_blocks_dict = {block:0 for block in block_list}\n",
    "    all_blocks_dict = getBlocks(projects, all_blocks_dict) \n",
    "    \n",
    "    for key in block_list: \n",
    "        userDict[key] = all_blocks_dict[key]\n",
    "    return userDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# blocks = set() \n",
    "# users = summaries.keys()\n",
    "# c = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# j = 0\n",
    "# for userID in users: \n",
    "#     i = 0\n",
    "#     userBlocks = set() \n",
    "\n",
    "#     projects = getAllProjects(userID, False)\n",
    "#     screenNames = getScreenNames(projects)\n",
    "\n",
    "#     while i < len(projects):\n",
    "#         for screenName in screenNames[i]:\n",
    "#                 if screenName in projects[i] and 'Active Blocks' in projects[i][screenName]['Blocks'] and 'Types' in projects[i][screenName]['Blocks']['Active Blocks']:\n",
    "#                     b = projects[i][screenName]['Blocks']['Active Blocks']['Types']\n",
    "#                     for block in b: \n",
    "#                         if block not in userBlocks: \n",
    "#                             userBlocks.add(block)\n",
    "#         i+=1\n",
    "    \n",
    "#     for block in userBlocks: \n",
    "#         if block not in blocks: \n",
    "#             if '.' in block: \n",
    "#                 b = block.split('.')[0]\n",
    "#             else: \n",
    "#                 b = block\n",
    "#             c[b] = 1\n",
    "#         else: \n",
    "#             c[b] +=1\n",
    "              \n",
    "#     j+=1 \n",
    "#     if j % 1000 == 0: \n",
    "#         print j,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('altered_blocks.json', 'w') as data_file:\n",
    "#     json.dump(c.keys(),data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# category_dict = {} \n",
    "# for block in c: \n",
    "#     if '.' in block: \n",
    "#         key = block.split('.')[0]\n",
    "#         if key not in category_dict:\n",
    "#             category_dict[key] = []\n",
    "#         category_dict[key].append(block)\n",
    "#     elif '_' in block: \n",
    "#         key = block.split('_')[0]\n",
    "#         if key not in category_dict: \n",
    "#             category_dict[key] = []\n",
    "#         category_dict[key].append(block)\n",
    "#     else: \n",
    "#         if 'other' not in category_dict:\n",
    "#             category_dict['other'] = []\n",
    "#         category_dict['other'].append(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print category_dict['lexical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('blocks_by_category.json', 'w') as data_file:\n",
    "#     json.dump(category_dict, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c = Counter(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for userID in users: \n",
    "#     projects = getAllProjects(userID, False)\n",
    "#     getBlocks(projects, all_blocks_dict)\n",
    "#     if i %1000 == 0: \n",
    "#         print i,\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_combined = combine_featfuncs([projectLengthFeatures, dayAnalysisFeatures,decileProjects])\n",
    "code_combined = combine_featfuncs([summaryOBlockDecile,summaryDecileTLBlocks,summaryDecileNumScreens,summaryDeltasTLBlocks,summaryDeltasOBlock,summaryDeltasNumScreens, summaryAverages, allBlocksFeaturizer])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmalurie/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:1110: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/Users/emmalurie/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "all_features = []\n",
    "time_features = [] \n",
    "code_features = []\n",
    "\n",
    "userlabels = get_user_labels()\n",
    "\n",
    "y = []\n",
    "ctr = 0\n",
    "for user in userlabels:\n",
    "    if user in not_tutorials: \n",
    "\n",
    "        projects = getAllProjects(user, filter_tutorials)  # this returns projects sorted by creation date that do notinclude tutorials \n",
    "\n",
    "        y.append(userlabels[user])\n",
    "\n",
    "        time_features.append(time_combined(projects))\n",
    "        code_features.append(code_combined(projects))\n",
    "\n",
    "\n",
    "        # merge time and code feature dicts\n",
    "        all_features_user = time_features[-1].copy()\n",
    "        all_features_user.update(code_features[-1])\n",
    "        all_features.append(all_features_user)\n",
    "\n",
    "        ctr+=1\n",
    "        if ctr%1000==0:\n",
    "            print ctr/1000,\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "y = numpy.array(y)\n",
    "\n",
    "timevec = DictVectorizer()\n",
    "\n",
    "Xtime = timevec.fit_transform(time_features, y) \n",
    "\n",
    "codevec = DictVectorizer()\n",
    "\n",
    "Xcode = codevec.fit_transform(code_features, y)\n",
    "\n",
    "allvec = DictVectorizer()\n",
    "\n",
    "Xall = allvec.fit_transform(all_features, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from numpy import *\n",
    "#convert to dense matrices since these are dense anyway\n",
    "Xtime = scale(Xtime.toarray())\n",
    "Xcode = scale(Xcode.toarray())\n",
    "Xall = scale(Xall.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static KFold Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if filter_tutorials:\n",
    "    with open('filtered_kfold.pickle', 'rb') as f:\n",
    "        foldindices = pickle.load(f)\n",
    "else:\n",
    "    with open('unfiltered_kfold.pickle', 'rb') as f:\n",
    "        foldindices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a logreg model with 22 time\n",
      "Fold 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 42490 is out of bounds for axis 1 with size 42490",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d46f412e6ab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'Fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 42490 is out of bounds for axis 1 with size 42490"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from  sklearn.metrics import f1_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from plotcnf import plot_confusion_matrix\n",
    "\n",
    "# print 'Chance is', max(numpy.bincount(y))/float(len(y))\n",
    "\n",
    "### added later ### ************************    \n",
    "#foldindices = StratifiedKFold(y)\n",
    "\n",
    "\n",
    "labels = map(lambda x:x[0], sorted(langgroup_num_map.items(), key=lambda x:x[1]))  \n",
    "# languages corresponding to class labels as a list\n",
    "\n",
    "    \n",
    "k = 70 #num neighbors for kNN\n",
    "\n",
    "classifiers = [('logreg', LogisticRegression())]  # no knn because it's too slow \n",
    "#multi_class='multinomial', \n",
    "   \n",
    "\n",
    "for modelname, model in classifiers:\n",
    "    #for featname, X in [('code', Xcode), ('all', Xall)]:\n",
    "    for featname, X in [('time', Xtime), ('code', Xcode), ('all', Xall)]:\n",
    "        print  'Building a', modelname, 'model with', X.shape[1], featname\n",
    "    \n",
    "        cvaccs = numpy.zeros(len(foldindices))\n",
    "        #cvf1 = numpy.zeros(len(foldindices))\n",
    "        for i, (trainidx, testidx) in enumerate(foldindices):\n",
    "            print 'Fold', i+1\n",
    "        \n",
    "            ytrain = y[trainidx]\n",
    "            ytest = y[testidx]\n",
    "        \n",
    "            Xtrain = X[trainidx, :]  \n",
    "            Xtest = X[testidx, :]\n",
    "            \n",
    "            pca = PCA(n_components=300)\n",
    "\n",
    "            reduced_train = pca.fit_transform(Xtrain)\n",
    "            reduced_test = pca.transform(Xtest)\n",
    "            \n",
    "            model.fit(reduced_train, reduced_test)\n",
    "            cvaccs[i] = model.score(Xtest, ytest)\n",
    "        \n",
    "            predictions = model.predict(reduced_test)\n",
    "            #cvf1[i] = f1_score(ytest, predictions)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print '****', modelname, cvaccs[i]\n",
    "        #analyze last fold only\n",
    "        cnf_matrix = confusion_matrix(ytest, predictions)  \n",
    "\n",
    "        plot_confusion_matrix(cnf_matrix, labels)\n",
    "        plt.show()\n",
    "        coef = model.coef_\n",
    "        print 'Average accuracy', numpy.mean(cvaccs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(zip(allvec.get_feature_names(), coef[0]), key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(ytest, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing get Blocks and normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeDict(d, projects): \n",
    "    '''normalizes dictionary by # of projects'''\n",
    "    np = numProjects(projects)\n",
    "    if float(np) == 0: np == 1\n",
    "    for entry in d: \n",
    "        try: \n",
    "            d[entry] = d[entry] / float(np)\n",
    "        except ZeroDivisionError: \n",
    "            print entry, np\n",
    "    return numpy.nan_to_num(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getBlocks2(projects, block_dict): \n",
    "    '''returns  a dictionary with the key as a block name ie math_add \n",
    "    and a value that is the # of occurances of that block / numProjects'''\n",
    "    screenNames = getScreenNames(projects)\n",
    "    i= 0\n",
    "    while i < len(projects):\n",
    "        for screenName in screenNames[i]:\n",
    "                if screenName in projects[i] and 'Active Blocks' in projects[i][screenName]['Blocks'] and 'Types' in projects[i][screenName]['Blocks']['Active Blocks']:\n",
    "                    blocks = projects[i][screenName]['Blocks']['Active Blocks']['Types']\n",
    "                    for block in blocks: \n",
    "                        if block in block_dict: \n",
    "                            block_dict[block] += projects[i][screenName]['Blocks']['Active Blocks']['Types'][block]\n",
    "                        try: \n",
    "                            if block.split(\".\")[0] in block_dict:\n",
    "                                block_dict[block.split(\".\")[0]] += projects[i][screenName]['Blocks']['Active Blocks']['Types'][block]\n",
    "                        except Error: \n",
    "                            pass\n",
    "\n",
    "        i+=1\n",
    "    final_dict = normalizeDict(block_dict, projects)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
